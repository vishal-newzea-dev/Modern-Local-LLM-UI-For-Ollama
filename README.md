# Ollama Local UI

A simple, cross-platform, and self-contained web UI for interacting with local Ollama models. Built with Go.

## Features
- Sleek, modern chat interface
- Automatically detects your installed Ollama models
- Saves chat history in your browser
- Allows deleting and switching between conversations
- Stop generation mid-response

## Install Ollama and an LLM locally
1.  Install Ollama here https://ollama.com/download
2.  Find a model here https://ollama.com/search

## How to Use
1.  Download the latest release for your operating system from the page.
2.  Unzip the file.
3.  Ensure the executable (`ollama-ui.exe` or `ollama-ui-linux`, etc.) and the `static` folder are in the same directory.
4.  Run the executable.
5.  Open your browser to `http://localhost:8081`.
